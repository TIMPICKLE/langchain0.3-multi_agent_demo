"""
ç ”ç©¶å‘˜Agent

ä¸“é—¨è´Ÿè´£ä¿¡æ¯æ”¶é›†ã€åˆ†æå’Œæ•´ç†çš„æ™ºèƒ½ä»£ç†ã€‚
ç ”ç©¶å‘˜Agentçš„ä¸»è¦èŒè´£ï¼š
1. æ”¶é›†ç›¸å…³ä¸»é¢˜çš„ä¿¡æ¯å’Œèµ„æ–™
2. åˆ†æä¿¡æ¯çš„å¯é æ€§å’Œç›¸å…³æ€§
3. æ•´ç†å¹¶ç»“æ„åŒ–ä¿¡æ¯
4. ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
"""
import asyncio
import json
from typing import Dict, Any, List
from datetime import datetime

from .base_agent import BaseAgent, TaskResult

class ResearcherAgent(BaseAgent):
    """
    ç ”ç©¶å‘˜Agent
    
    è¿™ä¸ªAgentä¸“é—¨è´Ÿè´£ä¿¡æ¯ç ”ç©¶å’Œåˆ†æå·¥ä½œã€‚å®ƒå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
    - ç³»ç»Ÿæ€§çš„ä¿¡æ¯æ”¶é›†èƒ½åŠ›
    - å®¢è§‚çš„åˆ†æå’Œè¯„ä¼°
    - ç»“æ„åŒ–çš„ä¿¡æ¯æ•´ç†
    - å¯é çš„ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self, agent_id: str = "researcher_001"):
        super().__init__(
            agent_id=agent_id,
            name="ç ”ç©¶å‘˜å°R",
            description="ä¸“ä¸šçš„ä¿¡æ¯ç ”ç©¶å’Œåˆ†æä¸“å®¶ï¼Œæ“…é•¿æ”¶é›†ã€æ•´ç†å’Œåˆ†æå„ç§ä¿¡æ¯èµ„æ–™"
        )
        
        # ç ”ç©¶å‘˜ä¸“ç”¨é…ç½®
        self.research_methods = [
            "æ–‡çŒ®è°ƒç ”", "æ•°æ®åˆ†æ", "æ¡ˆä¾‹ç ”ç©¶", "å¯¹æ¯”åˆ†æ", "è¶‹åŠ¿åˆ†æ"
        ]
        self.knowledge_domains = [
            "æŠ€æœ¯", "å•†ä¸š", "æ•™è‚²", "ç§‘å­¦", "ç¤¾ä¼š", "æ–‡åŒ–"
        ]
    
    def get_system_prompt(self) -> str:
        """è·å–ç ”ç©¶å‘˜çš„ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€åä¸“ä¸šçš„ç ”ç©¶å‘˜ï¼Œåå«å°Rã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯ï¼š

1. ä¿¡æ¯æ”¶é›†ä¸æ•´ç†ï¼š
   - ç³»ç»Ÿæ€§åœ°æ”¶é›†ç›¸å…³ä¸»é¢˜çš„ä¿¡æ¯
   - è¯†åˆ«å¯é å’Œæƒå¨çš„ä¿¡æ¯æº
   - æ•´ç†ä¿¡æ¯å¹¶å»é™¤é‡å¤å’Œå†—ä½™å†…å®¹

2. åˆ†æä¸è¯„ä¼°ï¼š
   - å®¢è§‚åˆ†æä¿¡æ¯çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§
   - è¯†åˆ«ä¿¡æ¯ä¹‹é—´çš„å…³è”å’Œæ¨¡å¼
   - è¯„ä¼°ä¿¡æ¯çš„é‡è¦æ€§å’Œä¼˜å…ˆçº§

3. æŠ¥å‘Šç”Ÿæˆï¼š
   - ç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Š
   - ä½¿ç”¨æ¸…æ™°çš„é€»è¾‘ç»“æ„
   - æä¾›å…·ä½“çš„æ•°æ®å’Œäº‹å®æ”¯æ’‘

å·¥ä½œåŸåˆ™ï¼š
- ä¿æŒå®¢è§‚å’Œä¸­ç«‹çš„æ€åº¦
- æ³¨é‡äº‹å®å’Œæ•°æ®
- ä½¿ç”¨ç³»ç»ŸåŒ–çš„ç ”ç©¶æ–¹æ³•
- ç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œå¯é æ€§

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- ä½¿ç”¨ç»“æ„åŒ–çš„æ ¼å¼ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ç­‰ï¼‰
- æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºå’Œå¯é æ€§
- æä¾›å…³é”®å‘ç°çš„æ€»ç»“
- åŒ…å«è¿›ä¸€æ­¥ç ”ç©¶çš„å»ºè®®"""
    
    async def process_task(self, task: Dict[str, Any]) -> TaskResult:
        """
        å¤„ç†ç ”ç©¶ä»»åŠ¡
        
        æ”¯æŒçš„ä»»åŠ¡ç±»å‹ï¼š
        - research_topic: ä¸»é¢˜ç ”ç©¶
        - analyze_data: æ•°æ®åˆ†æ
        - literature_review: æ–‡çŒ®ç»¼è¿°
        - fact_checking: äº‹å®æ ¸æŸ¥
        """
        task_id = task.get("id", f"research_{int(asyncio.get_event_loop().time())}")
        task_type = task.get("type", "research_topic")
        task_data = task.get("data", {})
        
        try:
            if task_type == "research_topic":
                result = await self._research_topic(task_data)
            elif task_type == "analyze_data":
                result = await self._analyze_data(task_data)
            elif task_type == "literature_review":
                result = await self._literature_review(task_data)
            elif task_type == "fact_checking":
                result = await self._fact_checking(task_data)
            else:
                result = await self._general_research(task_data)
            
            return TaskResult(
                agent_id=self.agent_id,
                task_id=task_id,
                status="success",
                result=result
            )
            
        except Exception as e:
            return TaskResult(
                agent_id=self.agent_id,
                task_id=task_id,
                status="failed",
                result=None,
                error_message=str(e)
            )
    
    async def _research_topic(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¸»é¢˜ç ”ç©¶
        
        Args:
            data: åŒ…å«ç ”ç©¶ä¸»é¢˜å’Œè¦æ±‚çš„æ•°æ®
            
        Returns:
            ç ”ç©¶æŠ¥å‘Š
        """
        topic = data.get("topic", "")
        scope = data.get("scope", "å…¨é¢")
        depth = data.get("depth", "ä¸­ç­‰")
        
        print(f"ğŸ” {self.name} æ­£åœ¨ç ”ç©¶ä¸»é¢˜: {topic}")
        
        # æ„å»ºç ”ç©¶æç¤ºè¯
        research_prompt = f"""
è¯·å¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œ{scope}çš„ç ”ç©¶åˆ†æï¼š

ç ”ç©¶ä¸»é¢˜ï¼š{topic}
ç ”ç©¶æ·±åº¦ï¼š{depth}
ç ”ç©¶èŒƒå›´ï¼š{scope}

è¯·æä¾›ä»¥ä¸‹å†…å®¹ï¼š

1. ä¸»é¢˜æ¦‚è¿°
   - å®šä¹‰å’ŒåŸºæœ¬æ¦‚å¿µ
   - ä¸»è¦ç‰¹ç‚¹å’Œç‰¹å¾
   - å‘å±•å†ç¨‹å’Œç°çŠ¶

2. å…³é”®è¦ç‚¹åˆ†æ
   - æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†
   - é‡è¦ç»„æˆéƒ¨åˆ†
   - å…³é”®æŠ€æœ¯æˆ–æ–¹æ³•

3. ç›¸å…³æ¡ˆä¾‹å’Œåº”ç”¨
   - å…¸å‹åº”ç”¨åœºæ™¯
   - æˆåŠŸæ¡ˆä¾‹åˆ†æ
   - å®é™…åº”ç”¨æ•ˆæœ

4. ä¼˜åŠ¿ä¸æŒ‘æˆ˜
   - ä¸»è¦ä¼˜åŠ¿å’Œä»·å€¼
   - é¢ä¸´çš„æŒ‘æˆ˜å’Œé—®é¢˜
   - è§£å†³æ–¹æ¡ˆå’Œæ”¹è¿›æ–¹å‘

5. å‘å±•è¶‹åŠ¿
   - æœªæ¥å‘å±•æ–¹å‘
   - æ–°å…´æŠ€æœ¯å’Œæ–¹æ³•
   - å¸‚åœºå‰æ™¯åˆ†æ

6. ç ”ç©¶æ€»ç»“
   - å…³é”®å‘ç°
   - é‡è¦ç»“è®º
   - è¿›ä¸€æ­¥ç ”ç©¶å»ºè®®

è¯·ç¡®ä¿ä¿¡æ¯å‡†ç¡®ã€ç»“æ„æ¸…æ™°ã€åˆ†ææ·±å…¥ã€‚
"""
        
        # è°ƒç”¨LLMè¿›è¡Œç ”ç©¶
        context = self.get_conversation_context()
        context.append({"role": "user", "content": research_prompt})
        
        research_result = self.call_llm(context)
        
        # æ„å»ºç»“æ„åŒ–ç»“æœ
        result = {
            "type": "topic_research",
            "topic": topic,
            "scope": scope,
            "depth": depth,
            "content": research_result,
            "metadata": {
                "research_methods": ["æ–‡çŒ®è°ƒç ”", "ä¿¡æ¯æ•´ç†", "åˆ†ææ€»ç»“"],
                "confidence_level": "é«˜",
                "completeness": "å®Œæ•´",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆä¸»é¢˜ç ”ç©¶: {topic}")
        return result
    
    async def _analyze_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ•°æ®åˆ†æ
        
        Args:
            data: åŒ…å«å¾…åˆ†ææ•°æ®çš„å­—å…¸
            
        Returns:
            æ•°æ®åˆ†ææŠ¥å‘Š
        """
        dataset = data.get("dataset", "")
        analysis_type = data.get("analysis_type", "æè¿°æ€§åˆ†æ")
        objectives = data.get("objectives", [])
        
        print(f"ğŸ“Š {self.name} æ­£åœ¨è¿›è¡Œæ•°æ®åˆ†æ")
        
        analysis_prompt = f"""
è¯·å¯¹ä»¥ä¸‹æ•°æ®è¿›è¡Œ{analysis_type}ï¼š

æ•°æ®å†…å®¹ï¼š
{dataset}

åˆ†æç›®æ ‡ï¼š
{', '.join(objectives) if objectives else 'å…¨é¢åˆ†ææ•°æ®ç‰¹å¾å’Œæ¨¡å¼'}

è¯·æä¾›ä»¥ä¸‹åˆ†æå†…å®¹ï¼š

1. æ•°æ®æ¦‚è§ˆ
   - æ•°æ®è§„æ¨¡å’Œç»“æ„
   - æ•°æ®è´¨é‡è¯„ä¼°
   - ä¸»è¦å­—æ®µè¯´æ˜

2. æè¿°æ€§ç»Ÿè®¡
   - åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
   - æ•°æ®åˆ†å¸ƒç‰¹å¾
   - å¼‚å¸¸å€¼è¯†åˆ«

3. æ¨¡å¼å‘ç°
   - æ•°æ®è¶‹åŠ¿åˆ†æ
   - å…³è”å…³ç³»è¯†åˆ«
   - èšç±»å’Œåˆ†ç»„

4. å…³é”®æ´å¯Ÿ
   - é‡è¦å‘ç°æ€»ç»“
   - ä¸šåŠ¡æ„ä¹‰è§£é‡Š
   - å¼‚å¸¸æƒ…å†µè¯´æ˜

5. ç»“è®ºå’Œå»ºè®®
   - ä¸»è¦ç»“è®º
   - è¡ŒåŠ¨å»ºè®®
   - è¿›ä¸€æ­¥åˆ†ææ–¹å‘

è¯·ç¡®ä¿åˆ†æå®¢è§‚å‡†ç¡®ï¼Œç»“è®ºæœ‰ç†æœ‰æ®ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": analysis_prompt})
        
        analysis_result = self.call_llm(context)
        
        result = {
            "type": "data_analysis",
            "analysis_type": analysis_type,
            "objectives": objectives,
            "content": analysis_result,
            "metadata": {
                "analysis_methods": ["æè¿°æ€§ç»Ÿè®¡", "æ¨¡å¼è¯†åˆ«", "è¶‹åŠ¿åˆ†æ"],
                "data_quality": "è‰¯å¥½",
                "confidence_level": "é«˜",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆæ•°æ®åˆ†æ")
        return result
    
    async def _literature_review(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–‡çŒ®ç»¼è¿°
        """
        topic = data.get("topic", "")
        timeframe = data.get("timeframe", "è¿‘5å¹´")
        focus_areas = data.get("focus_areas", [])
        
        print(f"ğŸ“š {self.name} æ­£åœ¨è¿›è¡Œæ–‡çŒ®ç»¼è¿°: {topic}")
        
        review_prompt = f"""
è¯·å¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œæ–‡çŒ®ç»¼è¿°ï¼š

ç»¼è¿°ä¸»é¢˜ï¼š{topic}
æ—¶é—´èŒƒå›´ï¼š{timeframe}
é‡ç‚¹é¢†åŸŸï¼š{', '.join(focus_areas) if focus_areas else 'å…¨é¢ç»¼è¿°'}

è¯·æä¾›ä»¥ä¸‹å†…å®¹ï¼š

1. ç ”ç©¶èƒŒæ™¯
   - ç ”ç©¶é—®é¢˜çš„é‡è¦æ€§
   - ç ”ç©¶é¢†åŸŸçš„å‘å±•å†ç¨‹
   - å½“å‰ç ”ç©¶ç°çŠ¶

2. ä¸»è¦ç ”ç©¶æ–¹å‘
   - æ ¸å¿ƒç ”ç©¶ä¸»é¢˜åˆ†ç±»
   - å„æ–¹å‘çš„ç ”ç©¶é‡ç‚¹
   - ä»£è¡¨æ€§ç ”ç©¶æˆæœ

3. ç ”ç©¶æ–¹æ³•æ¼”è¿›
   - ä¸»è¦ç ”ç©¶æ–¹æ³•
   - æ–¹æ³•è®ºå‘å±•è¶‹åŠ¿
   - æ–°å…´ç ”ç©¶å·¥å…·

4. å…³é”®å‘ç°æ±‡æ€»
   - é‡è¦ç ”ç©¶ç»“è®º
   - ä¸€è‡´æ€§å‘ç°
   - äº‰è®®æ€§é—®é¢˜

5. ç ”ç©¶ç©ºç™½è¯†åˆ«
   - å°šæœªè§£å†³çš„é—®é¢˜
   - ç ”ç©¶ç©ºç™½é¢†åŸŸ
   - æœªæ¥ç ”ç©¶æ–¹å‘

6. ç»¼è¿°æ€»ç»“
   - æ•´ä½“å‘å±•è¶‹åŠ¿
   - ä¸»è¦è´¡çŒ®æ€»ç»“
   - æœªæ¥ç ”ç©¶å»ºè®®

è¯·ç¡®ä¿è¦†ç›–å…¨é¢ï¼Œåˆ†æå®¢è§‚ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": review_prompt})
        
        review_result = self.call_llm(context)
        
        result = {
            "type": "literature_review",
            "topic": topic,
            "timeframe": timeframe,
            "focus_areas": focus_areas,
            "content": review_result,
            "metadata": {
                "review_scope": "ç»¼åˆæ€§",
                "coverage": "å…¨é¢",
                "quality": "é«˜",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆæ–‡çŒ®ç»¼è¿°")
        return result
    
    async def _fact_checking(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œäº‹å®æ ¸æŸ¥
        """
        statements = data.get("statements", [])
        sources = data.get("sources", [])
        
        print(f"ğŸ” {self.name} æ­£åœ¨è¿›è¡Œäº‹å®æ ¸æŸ¥")
        
        checking_prompt = f"""
è¯·å¯¹ä»¥ä¸‹é™ˆè¿°è¿›è¡Œäº‹å®æ ¸æŸ¥ï¼š

å¾…æ ¸æŸ¥é™ˆè¿°ï¼š
{json.dumps(statements, ensure_ascii=False, indent=2)}

å‚è€ƒæ¥æºï¼š
{json.dumps(sources, ensure_ascii=False, indent=2) if sources else 'è¯·åŸºäºå¸¸è¯†å’Œé€»è¾‘è¿›è¡Œåˆ¤æ–­'}

è¯·å¯¹æ¯ä¸ªé™ˆè¿°æä¾›ï¼š

1. äº‹å®æ ¸æŸ¥ç»“æœ
   - çœŸå®æ€§è¯„ä¼°ï¼ˆçœŸå®/éƒ¨åˆ†çœŸå®/è™šå‡/æ— æ³•ç¡®å®šï¼‰
   - å‡†ç¡®æ€§ç¨‹åº¦
   - å¯ä¿¡åº¦è¯„çº§

2. æ”¯æ’‘è¯æ®
   - ç›¸å…³äº‹å®å’Œæ•°æ®
   - å¯é ä¿¡æ¯æ¥æº
   - æƒå¨æœºæ„è§‚ç‚¹

3. é—®é¢˜åˆ†æ
   - é”™è¯¯æˆ–äº‰è®®ä¹‹å¤„
   - å¯èƒ½çš„è¯¯è§£åŸå› 
   - éœ€è¦æ¾„æ¸…çš„æ¦‚å¿µ

4. ä¿®æ­£å»ºè®®
   - å‡†ç¡®çš„è¡¨è¿°æ–¹å¼
   - è¡¥å……ä¿¡æ¯
   - æ³¨æ„äº‹é¡¹

è¯·ä¿æŒå®¢è§‚ä¸­ç«‹ï¼ŒåŸºäºäº‹å®è¿›è¡Œåˆ¤æ–­ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": checking_prompt})
        
        checking_result = self.call_llm(context)
        
        result = {
            "type": "fact_checking",
            "statements": statements,
            "sources": sources,
            "content": checking_result,
            "metadata": {
                "checking_criteria": ["å‡†ç¡®æ€§", "å¯é æ€§", "å®Œæ•´æ€§"],
                "verification_level": "ä¸¥æ ¼",
                "confidence": "é«˜",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆäº‹å®æ ¸æŸ¥")
        return result
    
    async def _general_research(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œé€šç”¨ç ”ç©¶ä»»åŠ¡
        """
        query = data.get("query", "")
        requirements = data.get("requirements", [])
        
        print(f"ğŸ” {self.name} æ­£åœ¨è¿›è¡Œé€šç”¨ç ”ç©¶")
        
        general_prompt = f"""
ç ”ç©¶è¯·æ±‚ï¼š{query}

ç‰¹æ®Šè¦æ±‚ï¼š
{json.dumps(requirements, ensure_ascii=False, indent=2) if requirements else 'æ ‡å‡†ç ”ç©¶æµç¨‹'}

è¯·æä¾›å…¨é¢çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

1. ä¸»é¢˜åˆ†æ
2. å…³é”®ä¿¡æ¯æ”¶é›†
3. ç›¸å…³æ¡ˆä¾‹ç ”ç©¶
4. é—®é¢˜å’ŒæŒ‘æˆ˜
5. è§£å†³æ–¹æ¡ˆå»ºè®®
6. æ€»ç»“å’Œç»“è®º

è¯·ç¡®ä¿ä¿¡æ¯å‡†ç¡®ã€åˆ†ææ·±å…¥ã€ç»“æ„æ¸…æ™°ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": general_prompt})
        
        research_result = self.call_llm(context)
        
        result = {
            "type": "general_research",
            "query": query,
            "requirements": requirements,
            "content": research_result,
            "metadata": {
                "research_approach": "ç»¼åˆæ€§",
                "completeness": "å…¨é¢",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆé€šç”¨ç ”ç©¶")
        return result
    
    def get_research_capabilities(self) -> Dict[str, Any]:
        """è·å–ç ”ç©¶èƒ½åŠ›æè¿°"""
        return {
            "supported_tasks": [
                "research_topic",
                "analyze_data", 
                "literature_review",
                "fact_checking",
                "general_research"
            ],
            "research_methods": self.research_methods,
            "knowledge_domains": self.knowledge_domains,
            "output_formats": ["æŠ¥å‘Š", "åˆ†æ", "ç»¼è¿°", "æ ¸æŸ¥ç»“æœ"],
            "quality_standards": ["å‡†ç¡®æ€§", "å®¢è§‚æ€§", "å®Œæ•´æ€§", "å¯è¯»æ€§"]
        }
