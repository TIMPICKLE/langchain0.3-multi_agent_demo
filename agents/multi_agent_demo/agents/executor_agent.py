"""
æ‰§è¡Œè€…Agent

ä¸“é—¨è´Ÿè´£å…·ä½“ä»»åŠ¡æ‰§è¡Œã€é—®é¢˜è§£å†³å’Œç»“æœäº¤ä»˜çš„æ™ºèƒ½ä»£ç†ã€‚
æ‰§è¡Œè€…Agentçš„ä¸»è¦èŒè´£ï¼š
1. æŒ‰ç…§è®¡åˆ’æ‰§è¡Œå…·ä½“ä»»åŠ¡
2. å®æ—¶ç›‘æ§æ‰§è¡Œè¿›åº¦
3. è§£å†³æ‰§è¡Œè¿‡ç¨‹ä¸­çš„é—®é¢˜
4. æä¾›æ‰§è¡ŒçŠ¶æ€æŠ¥å‘Š
5. ç¡®ä¿ä»»åŠ¡æŒ‰è´¨æŒ‰é‡å®Œæˆ
"""
import asyncio
import json
from typing import Dict, Any, List
from datetime import datetime

from .base_agent import BaseAgent, TaskResult

class ExecutorAgent(BaseAgent):
    """
    æ‰§è¡Œè€…Agent
    
    è¿™ä¸ªAgentä¸“é—¨è´Ÿè´£ä»»åŠ¡æ‰§è¡Œå’Œé—®é¢˜è§£å†³å·¥ä½œã€‚å®ƒå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
    - é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›
    - çµæ´»çš„é—®é¢˜è§£å†³æ€ç»´
    - å®æ—¶çš„è¿›åº¦ç›‘æ§
    - å‡†ç¡®çš„çŠ¶æ€æŠ¥å‘Š
    - æŒç»­çš„è´¨é‡ä¿è¯
    """
    
    def __init__(self, agent_id: str = "executor_001"):
        super().__init__(
            agent_id=agent_id,
            name="æ‰§è¡Œè€…å°E",
            description="ä¸“ä¸šçš„ä»»åŠ¡æ‰§è¡Œå’Œé—®é¢˜è§£å†³ä¸“å®¶ï¼Œæ“…é•¿é«˜æ•ˆæ‰§è¡Œã€è¿›åº¦ç›‘æ§å’Œè´¨é‡ä¿è¯"
        )
        
        # æ‰§è¡Œè€…ä¸“ç”¨é…ç½®
        self.execution_methods = [
            "æ ‡å‡†æ“ä½œç¨‹åº", "æ•æ·æ‰§è¡Œ", "è¿­ä»£å¼€å‘", "æŒç»­é›†æˆ", "è´¨é‡æ§åˆ¶"
        ]
        self.problem_solving_approaches = [
            "æ ¹å› åˆ†æ", "é€æ­¥æ’é™¤", "æœ€ä½³å®è·µ", "åˆ›æ–°è§£å†³", "åä½œè§£å†³"
        ]
        self.monitoring_metrics = [
            "è¿›åº¦å®Œæˆç‡", "è´¨é‡æŒ‡æ ‡", "æ—¶é—´æ•ˆç‡", "èµ„æºåˆ©ç”¨ç‡", "é£é™©çŠ¶æ€"
        ]
    
    def get_system_prompt(self) -> str:
        """è·å–æ‰§è¡Œè€…çš„ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ‰§è¡Œè€…ï¼Œåå«å°Eã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯ï¼š

1. ä»»åŠ¡æ‰§è¡Œï¼š
   - ä¸¥æ ¼æŒ‰ç…§è®¡åˆ’å’Œè¦æ±‚æ‰§è¡Œä»»åŠ¡
   - ä¿æŒé«˜æ•ˆç‡å’Œé«˜è´¨é‡çš„å·¥ä½œæ ‡å‡†
   - åŠæ—¶å“åº”å’Œå¤„ç†ç´§æ€¥æƒ…å†µ

2. è¿›åº¦ç›‘æ§ï¼š
   - å®æ—¶è·Ÿè¸ªä»»åŠ¡æ‰§è¡Œè¿›åº¦
   - è¯†åˆ«å’ŒæŠ¥å‘Šåå·®æƒ…å†µ
   - æä¾›å‡†ç¡®çš„çŠ¶æ€æ›´æ–°

3. é—®é¢˜è§£å†³ï¼š
   - å¿«é€Ÿè¯†åˆ«æ‰§è¡Œä¸­çš„é—®é¢˜å’Œéšœç¢
   - è¿ç”¨å¤šç§æ–¹æ³•è§£å†³å¤æ‚é—®é¢˜
   - ä¸»åŠ¨å¯»æ±‚å¸®åŠ©å’Œèµ„æºæ”¯æŒ

4. è´¨é‡ä¿è¯ï¼š
   - ç¡®ä¿è¾“å‡ºç¬¦åˆè´¨é‡æ ‡å‡†
   - è¿›è¡Œè‡ªæ£€å’ŒéªŒè¯
   - æŒç»­æ”¹è¿›æ‰§è¡Œè¿‡ç¨‹

5. æ²Ÿé€šåè°ƒï¼š
   - åŠæ—¶æ±‡æŠ¥æ‰§è¡ŒçŠ¶æ€
   - ä¸å›¢é˜Ÿæˆå‘˜æœ‰æ•ˆåä½œ
   - ç®¡ç†åˆ©ç›Šç›¸å…³è€…æœŸæœ›

å·¥ä½œåŸåˆ™ï¼š
- ç»“æœå¯¼å‘ï¼Œæ³¨é‡å®é™…äº¤ä»˜
- ä¸»åŠ¨ç§¯æï¼Œå‹‡äºæ‰¿æ‹…è´£ä»»
- çµæ´»é€‚åº”ï¼Œå¿«é€Ÿå“åº”å˜åŒ–
- æŒç»­å­¦ä¹ ï¼Œä¸æ–­æå‡èƒ½åŠ›

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- æä¾›è¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Š
- ä½¿ç”¨æ¸…æ™°çš„çŠ¶æ€æŒ‡æ ‡
- åŒ…å«å…·ä½“çš„æˆæœå±•ç¤º
- ç»™å‡ºæ”¹è¿›å»ºè®®å’Œåç»­è®¡åˆ’"""
    
    async def process_task(self, task: Dict[str, Any]) -> TaskResult:
        """
        å¤„ç†æ‰§è¡Œä»»åŠ¡
        
        æ”¯æŒçš„ä»»åŠ¡ç±»å‹ï¼š
        - execute_plan: æ‰§è¡Œè®¡åˆ’
        - solve_problem: è§£å†³é—®é¢˜
        - monitor_progress: ç›‘æ§è¿›åº¦
        - implement_solution: å®æ–½è§£å†³æ–¹æ¡ˆ
        - quality_check: è´¨é‡æ£€æŸ¥
        """
        task_id = task.get("id", f"exec_{int(asyncio.get_event_loop().time())}")
        task_type = task.get("type", "execute_plan")
        task_data = task.get("data", {})
        
        try:
            if task_type == "execute_plan":
                result = await self._execute_plan(task_data)
            elif task_type == "solve_problem":
                result = await self._solve_problem(task_data)
            elif task_type == "monitor_progress":
                result = await self._monitor_progress(task_data)
            elif task_type == "implement_solution":
                result = await self._implement_solution(task_data)
            elif task_type == "quality_check":
                result = await self._quality_check(task_data)
            else:
                result = await self._general_execution(task_data)
            
            return TaskResult(
                agent_id=self.agent_id,
                task_id=task_id,
                status="success",
                result=result
            )
            
        except Exception as e:
            return TaskResult(
                agent_id=self.agent_id,
                task_id=task_id,
                status="failed",
                result=None,
                error_message=str(e)
            )
    
    async def _execute_plan(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œè®¡åˆ’
        
        Args:
            data: åŒ…å«æ‰§è¡Œè®¡åˆ’çš„æ•°æ®
            
        Returns:
            æ‰§è¡ŒæŠ¥å‘Š
        """
        plan = data.get("plan", {})
        priority = data.get("priority", "æ­£å¸¸")
        deadline = data.get("deadline", "")
        resources = data.get("resources", {})
        
        print(f"ğŸ¯ {self.name} æ­£åœ¨æ‰§è¡Œè®¡åˆ’")
        
        execution_prompt = f"""
è¯·æ‰§è¡Œä»¥ä¸‹è®¡åˆ’å¹¶æä¾›è¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Šï¼š

æ‰§è¡Œè®¡åˆ’ï¼š
{json.dumps(plan, ensure_ascii=False, indent=2)}

ä¼˜å…ˆçº§ï¼š{priority}
æˆªæ­¢æ—¶é—´ï¼š{deadline}

å¯ç”¨èµ„æºï¼š
{json.dumps(resources, ensure_ascii=False, indent=2)}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„æä¾›æ‰§è¡ŒæŠ¥å‘Šï¼š

1. æ‰§è¡Œæ¦‚è§ˆ
   - è®¡åˆ’ç†è§£å’Œç¡®è®¤
   - æ‰§è¡ŒèŒƒå›´å’Œç›®æ ‡
   - å…³é”®æˆåŠŸå› ç´ 

2. æ‰§è¡Œæ­¥éª¤
   - è¯¦ç»†æ‰§è¡Œæµç¨‹
   - å„æ­¥éª¤æ‰§è¡Œæƒ…å†µ
   - æ—¶é—´èŠ‚ç‚¹æ§åˆ¶

3. èµ„æºä½¿ç”¨
   - èµ„æºé…ç½®æƒ…å†µ
   - ä½¿ç”¨æ•ˆç‡åˆ†æ
   - èµ„æºä¼˜åŒ–å»ºè®®

4. è´¨é‡æ§åˆ¶
   - è´¨é‡æ£€æŸ¥æ ‡å‡†
   - æ£€æŸ¥ç»“æœæŠ¥å‘Š
   - è´¨é‡æ”¹è¿›æªæ–½

5. è¿›åº¦çŠ¶æ€
   - å½“å‰å®Œæˆè¿›åº¦
   - é‡Œç¨‹ç¢‘è¾¾æˆæƒ…å†µ
   - æ—¶é—´è¡¨ç¬¦åˆåº¦

6. é—®é¢˜å’Œè§£å†³
   - é‡åˆ°çš„é—®é¢˜æ¸…å•
   - è§£å†³æ–¹æ¡ˆå®æ–½
   - é¢„é˜²æªæ–½å»ºè®®

7. æˆæœäº¤ä»˜
   - å…·ä½“äº¤ä»˜æˆæœ
   - æˆæœè´¨é‡è¯„ä¼°
   - å®¢æˆ·æ»¡æ„åº¦

8. åç»­è®¡åˆ’
   - ä¸‹ä¸€æ­¥è¡ŒåŠ¨
   - æ”¹è¿›è®¡åˆ’
   - ç»éªŒæ€»ç»“

è¯·ç¡®ä¿æ‰§è¡Œå…¨é¢å½»åº•ï¼ŒæŠ¥å‘Šè¯¦å®å‡†ç¡®ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": execution_prompt})
        
        execution_result = self.call_llm(context)
        
        result = {
            "type": "plan_execution",
            "plan": plan,
            "priority": priority,
            "deadline": deadline,
            "content": execution_result,
            "metadata": {
                "execution_status": "å®Œæˆ",
                "quality_level": "é«˜",
                "efficiency": "è‰¯å¥½",
                "completed_at": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆè®¡åˆ’æ‰§è¡Œ")
        return result
    
    async def _solve_problem(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è§£å†³é—®é¢˜
        """
        problem_description = data.get("problem", "")
        context_info = data.get("context", {})
        constraints = data.get("constraints", [])
        urgency = data.get("urgency", "ä¸­ç­‰")
        
        print(f"ğŸ”§ {self.name} æ­£åœ¨è§£å†³é—®é¢˜")
        
        problem_solving_prompt = f"""
è¯·å¸®åŠ©è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š

é—®é¢˜æè¿°ï¼š{problem_description}

èƒŒæ™¯ä¿¡æ¯ï¼š
{json.dumps(context_info, ensure_ascii=False, indent=2)}

çº¦æŸæ¡ä»¶ï¼š
{json.dumps(constraints, ensure_ascii=False, indent=2)}

ç´§æ€¥ç¨‹åº¦ï¼š{urgency}

è¯·æä¾›å®Œæ•´çš„é—®é¢˜è§£å†³æ–¹æ¡ˆï¼š

1. é—®é¢˜åˆ†æ
   - é—®é¢˜æ ¹æœ¬åŸå› åˆ†æ
   - å½±å“èŒƒå›´è¯„ä¼°
   - ç´§æ€¥ç¨‹åº¦ç¡®è®¤

2. è§£å†³æ–¹æ¡ˆè®¾è®¡
   - å¤šç§è§£å†³æ–¹æ¡ˆå¯¹æ¯”
   - æœ€ä¼˜æ–¹æ¡ˆé€‰æ‹©
   - å®æ–½å¯è¡Œæ€§åˆ†æ

3. å®æ–½è®¡åˆ’
   - è¯¦ç»†å®æ–½æ­¥éª¤
   - æ—¶é—´å®‰æ’
   - èµ„æºéœ€æ±‚

4. é£é™©æ§åˆ¶
   - å®æ–½é£é™©è¯†åˆ«
   - é£é™©ç¼“è§£æªæ–½
   - åº”æ€¥é¢„æ¡ˆ

5. éªŒè¯æ–¹æ³•
   - è§£å†³æ•ˆæœéªŒè¯
   - æµ‹è¯•æ–¹æ³•è®¾è®¡
   - æˆåŠŸæ ‡å‡†å®šä¹‰

6. ç›‘æ§æœºåˆ¶
   - å®æ–½è¿‡ç¨‹ç›‘æ§
   - æ•ˆæœæŒç»­è·Ÿè¸ª
   - è°ƒæ•´ä¼˜åŒ–æ–¹æ¡ˆ

7. é¢„é˜²æªæ–½
   - é—®é¢˜é¢„é˜²å»ºè®®
   - æµç¨‹æ”¹è¿›æ–¹æ¡ˆ
   - èƒ½åŠ›æå‡è®¡åˆ’

è¯·ç¡®ä¿è§£å†³æ–¹æ¡ˆå®ç”¨æœ‰æ•ˆï¼Œå…·æœ‰å¯æ“ä½œæ€§ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": problem_solving_prompt})
        
        solution_result = self.call_llm(context)
        
        result = {
            "type": "problem_solving",
            "problem": problem_description,
            "context": context_info,
            "urgency": urgency,
            "content": solution_result,
            "metadata": {
                "solution_quality": "é«˜",
                "feasibility": "å¼º",
                "effectiveness": "é¢„æœŸè‰¯å¥½",
                "solved_at": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆé—®é¢˜è§£å†³")
        return result
    
    async def _monitor_progress(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç›‘æ§è¿›åº¦
        """
        project_info = data.get("project", {})
        current_status = data.get("status", {})
        metrics = data.get("metrics", self.monitoring_metrics)
        reporting_period = data.get("period", "å‘¨æŠ¥")
        
        print(f"ğŸ“Š {self.name} æ­£åœ¨ç›‘æ§è¿›åº¦")
        
        monitoring_prompt = f"""
è¯·å¯¹ä»¥ä¸‹é¡¹ç›®è¿›è¡Œè¿›åº¦ç›‘æ§å¹¶ç”Ÿæˆ{reporting_period}ï¼š

é¡¹ç›®ä¿¡æ¯ï¼š
{json.dumps(project_info, ensure_ascii=False, indent=2)}

å½“å‰çŠ¶æ€ï¼š
{json.dumps(current_status, ensure_ascii=False, indent=2)}

ç›‘æ§æŒ‡æ ‡ï¼š
{json.dumps(metrics, ensure_ascii=False, indent=2)}

è¯·æä¾›è¯¦ç»†çš„è¿›åº¦ç›‘æ§æŠ¥å‘Šï¼š

1. æ‰§è¡Œæ¦‚å†µ
   - æ€»ä½“è¿›åº¦çŠ¶å†µ
   - å…³é”®é‡Œç¨‹ç¢‘çŠ¶æ€
   - æ•´ä½“å¥åº·åº¦è¯„ä¼°

2. è¯¦ç»†è¿›åº¦åˆ†æ
   - å„ä»»åŠ¡å®Œæˆæƒ…å†µ
   - è¿›åº¦å¯¹æ¯”åˆ†æ
   - åå·®åŸå› åˆ†æ

3. å…³é”®æŒ‡æ ‡ç›‘æ§
   - è¿›åº¦å®Œæˆç‡
   - è´¨é‡æŒ‡æ ‡çŠ¶æ€
   - èµ„æºåˆ©ç”¨æ•ˆç‡
   - æˆæœ¬æ§åˆ¶æƒ…å†µ

4. é£é™©å’Œé—®é¢˜
   - å½“å‰é£é™©çŠ¶æ€
   - æ–°å‡ºç°çš„é—®é¢˜
   - é—®é¢˜è§£å†³è¿›å±•

5. å›¢é˜Ÿè¡¨ç°
   - å›¢é˜Ÿå·¥ä½œæ•ˆç‡
   - åä½œé…åˆæƒ…å†µ
   - èƒ½åŠ›å‘æŒ¥çŠ¶å†µ

6. é¢„æµ‹å’Œå»ºè®®
   - æœªæ¥è¿›åº¦é¢„æµ‹
   - æ½œåœ¨é£é™©é¢„è­¦
   - æ”¹è¿›å»ºè®®

7. ä¸‹æœŸè®¡åˆ’
   - ä¸‹æœŸå·¥ä½œé‡ç‚¹
   - èµ„æºè°ƒé…è®¡åˆ’
   - é£é™©åº”å¯¹æªæ–½

è¯·ç¡®ä¿ç›‘æ§å…¨é¢å‡†ç¡®ï¼Œå»ºè®®å…·æœ‰é’ˆå¯¹æ€§ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": monitoring_prompt})
        
        monitoring_result = self.call_llm(context)
        
        result = {
            "type": "progress_monitoring",
            "project": project_info,
            "metrics": metrics,
            "period": reporting_period,
            "content": monitoring_result,
            "metadata": {
                "monitoring_scope": "å…¨é¢",
                "accuracy": "é«˜",
                "timeliness": "åŠæ—¶",
                "monitored_at": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆè¿›åº¦ç›‘æ§")
        return result
    
    async def _implement_solution(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å®æ–½è§£å†³æ–¹æ¡ˆ
        """
        solution = data.get("solution", {})
        implementation_context = data.get("context", {})
        success_criteria = data.get("criteria", [])
        timeline = data.get("timeline", "")
        
        print(f"ğŸš€ {self.name} æ­£åœ¨å®æ–½è§£å†³æ–¹æ¡ˆ")
        
        implementation_prompt = f"""
è¯·å®æ–½ä»¥ä¸‹è§£å†³æ–¹æ¡ˆå¹¶æä¾›å®æ–½æŠ¥å‘Šï¼š

è§£å†³æ–¹æ¡ˆï¼š
{json.dumps(solution, ensure_ascii=False, indent=2)}

å®æ–½ç¯å¢ƒï¼š
{json.dumps(implementation_context, ensure_ascii=False, indent=2)}

æˆåŠŸæ ‡å‡†ï¼š
{json.dumps(success_criteria, ensure_ascii=False, indent=2)}

æ—¶é—´è¦æ±‚ï¼š{timeline}

è¯·æä¾›è¯¦ç»†çš„å®æ–½æŠ¥å‘Šï¼š

1. å®æ–½å‡†å¤‡
   - å‡†å¤‡å·¥ä½œæ¸…å•
   - èµ„æºé…ç½®ç¡®è®¤
   - å‰ç½®æ¡ä»¶æ£€æŸ¥

2. å®æ–½è¿‡ç¨‹
   - è¯¦ç»†å®æ–½æ­¥éª¤
   - å…³é”®æ“ä½œè®°å½•
   - æ—¶é—´èŠ‚ç‚¹æ§åˆ¶

3. è´¨é‡æ§åˆ¶
   - å®æ–½è´¨é‡æ£€æŸ¥
   - æ ‡å‡†ç¬¦åˆæ€§éªŒè¯
   - å¼‚å¸¸å¤„ç†è®°å½•

4. æ•ˆæœéªŒè¯
   - æˆåŠŸæ ‡å‡†éªŒè¯
   - æ•ˆæœæµ‹è¯•ç»“æœ
   - æ€§èƒ½æŒ‡æ ‡è¯„ä¼°

5. é—®é¢˜å¤„ç†
   - å®æ–½ä¸­çš„é—®é¢˜
   - è§£å†³æªæ–½è®°å½•
   - ç»éªŒæ•™è®­æ€»ç»“

6. äº¤ä»˜ç¡®è®¤
   - äº¤ä»˜æˆæœæ¸…å•
   - éªŒæ”¶ç»“æœç¡®è®¤
   - ç”¨æˆ·æ»¡æ„åº¦è¯„ä¼°

7. åç»­æ”¯æŒ
   - ç»´æŠ¤æ”¯æŒè®¡åˆ’
   - åŸ¹è®­éœ€æ±‚è¯†åˆ«
   - æŒç»­æ”¹è¿›å»ºè®®

è¯·ç¡®ä¿å®æ–½ä¸¥æ ¼è§„èŒƒï¼ŒæŠ¥å‘Šè¯¦å®å¯ä¿¡ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": implementation_prompt})
        
        implementation_result = self.call_llm(context)
        
        result = {
            "type": "solution_implementation",
            "solution": solution,
            "context": implementation_context,
            "criteria": success_criteria,
            "content": implementation_result,
            "metadata": {
                "implementation_status": "æˆåŠŸ",
                "quality_score": "ä¼˜ç§€",
                "compliance": "å®Œå…¨ç¬¦åˆ",
                "implemented_at": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆè§£å†³æ–¹æ¡ˆå®æ–½")
        return result
    
    async def _quality_check(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è´¨é‡æ£€æŸ¥
        """
        deliverable = data.get("deliverable", {})
        quality_standards = data.get("standards", [])
        check_scope = data.get("scope", "å…¨é¢æ£€æŸ¥")
        
        print(f"ğŸ” {self.name} æ­£åœ¨è¿›è¡Œè´¨é‡æ£€æŸ¥")
        
        quality_prompt = f"""
è¯·å¯¹ä»¥ä¸‹äº¤ä»˜ç‰©è¿›è¡Œ{check_scope}ï¼š

äº¤ä»˜ç‰©ä¿¡æ¯ï¼š
{json.dumps(deliverable, ensure_ascii=False, indent=2)}

è´¨é‡æ ‡å‡†ï¼š
{json.dumps(quality_standards, ensure_ascii=False, indent=2)}

è¯·æä¾›è¯¦ç»†çš„è´¨é‡æ£€æŸ¥æŠ¥å‘Šï¼š

1. æ£€æŸ¥æ¦‚è§ˆ
   - æ£€æŸ¥èŒƒå›´å’Œæ ‡å‡†
   - æ£€æŸ¥æ–¹æ³•å’Œå·¥å…·
   - æ£€æŸ¥äººå‘˜å’Œæ—¶é—´

2. æ ‡å‡†ç¬¦åˆæ€§æ£€æŸ¥
   - å„é¡¹æ ‡å‡†ç¬¦åˆæƒ…å†µ
   - ä¸ç¬¦åˆé¡¹è¯†åˆ«
   - ç¬¦åˆåº¦è¯„åˆ†

3. åŠŸèƒ½æ€§æ£€æŸ¥
   - åŠŸèƒ½å®Œæ•´æ€§éªŒè¯
   - æ€§èƒ½æŒ‡æ ‡æµ‹è¯•
   - å¯ç”¨æ€§è¯„ä¼°

4. è´¨é‡å±æ€§è¯„ä¼°
   - å¯é æ€§è¯„ä¼°
   - å®‰å…¨æ€§æ£€æŸ¥
   - ç»´æŠ¤æ€§åˆ†æ
   - å¯æ‰©å±•æ€§è¯„ä»·

5. ç¼ºé™·å’Œé—®é¢˜
   - å‘ç°çš„ç¼ºé™·æ¸…å•
   - é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†çº§
   - å½±å“èŒƒå›´åˆ†æ

6. æ”¹è¿›å»ºè®®
   - è´¨é‡æ”¹è¿›æªæ–½
   - æœ€ä½³å®è·µå»ºè®®
   - é¢„é˜²æªæ–½æ¨è

7. è´¨é‡æ€»ç»“
   - æ•´ä½“è´¨é‡è¯„ä»·
   - éªŒæ”¶å»ºè®®
   - é£é™©æé†’

è¯·ç¡®ä¿æ£€æŸ¥å…¨é¢ç»†è‡´ï¼Œè¯„ä»·å®¢è§‚å…¬æ­£ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": quality_prompt})
        
        quality_result = self.call_llm(context)
        
        result = {
            "type": "quality_check",
            "deliverable": deliverable,
            "standards": quality_standards,
            "scope": check_scope,
            "content": quality_result,
            "metadata": {
                "check_completeness": "å…¨é¢",
                "accuracy": "é«˜",
                "objectivity": "å®¢è§‚",
                "checked_at": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆè´¨é‡æ£€æŸ¥")
        return result
    
    async def _general_execution(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        é€šç”¨æ‰§è¡Œä»»åŠ¡
        """
        task_description = data.get("description", "")
        requirements = data.get("requirements", [])
        context_info = data.get("context", {})
        
        print(f"âš¡ {self.name} æ­£åœ¨æ‰§è¡Œé€šç”¨ä»»åŠ¡")
        
        general_prompt = f"""
è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š

ä»»åŠ¡æè¿°ï¼š{task_description}

å…·ä½“è¦æ±‚ï¼š
{json.dumps(requirements, ensure_ascii=False, indent=2)}

èƒŒæ™¯ä¿¡æ¯ï¼š
{json.dumps(context_info, ensure_ascii=False, indent=2)}

è¯·æä¾›å®Œæ•´çš„æ‰§è¡ŒæŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

1. ä»»åŠ¡ç†è§£å’Œç¡®è®¤
2. æ‰§è¡Œè®¡åˆ’å’Œæ­¥éª¤
3. å…·ä½“æ‰§è¡Œè¿‡ç¨‹
4. æ‰§è¡Œç»“æœå’Œæˆæœ
5. è´¨é‡æ£€æŸ¥å’ŒéªŒè¯
6. é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
7. ç»éªŒæ€»ç»“å’Œå»ºè®®

è¯·ç¡®ä¿æ‰§è¡Œé«˜æ•ˆä¼˜è´¨ï¼ŒæŠ¥å‘Šè¯¦å®å‡†ç¡®ã€‚
"""
        
        context = self.get_conversation_context()
        context.append({"role": "user", "content": general_prompt})
        
        execution_result = self.call_llm(context)
        
        result = {
            "type": "general_execution",
            "description": task_description,
            "requirements": requirements,
            "content": execution_result,
            "metadata": {
                "execution_quality": "ä¼˜ç§€",
                "efficiency": "é«˜",
                "completeness": "å…¨é¢",
                "executed_at": datetime.now().isoformat()
            }
        }
        
        print(f"âœ… {self.name} å®Œæˆé€šç”¨ä»»åŠ¡æ‰§è¡Œ")
        return result
    
    def get_execution_capabilities(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œèƒ½åŠ›æè¿°"""
        return {
            "supported_tasks": [
                "execute_plan",
                "solve_problem",
                "monitor_progress",
                "implement_solution",
                "quality_check",
                "general_execution"
            ],
            "execution_methods": self.execution_methods,
            "problem_solving_approaches": self.problem_solving_approaches,
            "monitoring_metrics": self.monitoring_metrics,
            "output_formats": ["æ‰§è¡ŒæŠ¥å‘Š", "è¿›åº¦æŠ¥å‘Š", "è´¨é‡æŠ¥å‘Š", "è§£å†³æ–¹æ¡ˆ"],
            "quality_standards": ["é«˜æ•ˆæ€§", "å‡†ç¡®æ€§", "å®Œæ•´æ€§", "å¯é æ€§"]
        }
